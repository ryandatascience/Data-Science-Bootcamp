{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Decision Trees:\n",
    "\n",
    "1. Decision Trees (DTs) are a _non-parametric supervised_ learning method\n",
    "2. Used for _classification_ and _regression_. \n",
    "3. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    " Data in the form of :    $(X,Y)=(x_{1},x_{2},x_{3},...,x_{k},Y)$ \n",
    "\n",
    "Where Input Samples are given in the shape of an array of shape (n_samples, n_features)\n",
    "\n",
    "And Output values are given as an array of shape (n_samples,)\n",
    "\n",
    "The goal is to build an Estimator :  $\\phi_{L} : X \\rightarrow  y$ minimizing :\n",
    "\n",
    "Err ($\\phi_{L}) = E_{X,Y} \\{L (Y, \\phi_{L}.predict(X))\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/images/1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Tree : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/images/2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.1 Using Scikit Learn for DTs (Growing  a Tree)\n",
    "\n",
    "A tree is grown iteratively from top to down by choosing a variable at each step that _best splits_ the set of items. \n",
    "\n",
    "### Gini Impurity :\n",
    " $I_{G}(f)=\\sum _{i=1}^{J}f_{i}(1-f_{i})=\\sum _{i=1}^{J}(f_{i}-{f_{i}}^{2})=\\sum _{i=1}^{J}f_{i}-\\sum _{i=1}^{J}{f_{i}}^{2}=1-\\sum _{i=1}^{J}{f_{i}}^{2}=\\sum _{i\\neq k}f_{i}f_{k}$\n",
    "\n",
    "### Information Gain (IG)\n",
    "$H(T)=I_{E}(p_{1},p_{2},...,p_{n})=-\\sum _{i=1}^{J}p_{i}\\log _{2}^{}p_{i}$\n",
    "\n",
    "$IG(T,a) = H(T) - H(T|a)$\n",
    "\n",
    "\n",
    "\n",
    "### Classification Models: \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit\n",
    "\n",
    "class sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, class_weight=None, presort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/images/3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Titanic Example: \n",
    "\n",
    "Given a certain set of parameters about a passenger, can we predict whether he/she will survive or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Downloading Packages:\n",
    "\n",
    "First, we import some pacakges that we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# Importing the Relevant Packages                                   #\n",
    "#####################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer, LabelBinarizer, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "#import xgboost as xgb\n",
    "#import keras as krs\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import graphviz as gv\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "#import pandoc\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "sns.set(font_scale=1.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Importing, Pruning and visualizing the Data: \n",
    "\n",
    "Now we will import the data set from input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "5              6         0       3   \n",
      "6              7         0       1   \n",
      "7              8         0       3   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "10            11         1       3   \n",
      "11            12         1       1   \n",
      "12            13         0       3   \n",
      "13            14         0       3   \n",
      "14            15         0       3   \n",
      "15            16         1       2   \n",
      "16            17         0       3   \n",
      "17            18         1       2   \n",
      "18            19         0       3   \n",
      "19            20         1       3   \n",
      "20            21         0       2   \n",
      "21            22         1       2   \n",
      "22            23         1       3   \n",
      "23            24         1       1   \n",
      "24            25         0       3   \n",
      "25            26         1       3   \n",
      "26            27         0       3   \n",
      "27            28         0       1   \n",
      "28            29         1       3   \n",
      "29            30         0       3   \n",
      "..           ...       ...     ...   \n",
      "861          862         0       2   \n",
      "862          863         1       1   \n",
      "863          864         0       3   \n",
      "864          865         0       2   \n",
      "865          866         1       2   \n",
      "866          867         1       2   \n",
      "867          868         0       1   \n",
      "868          869         0       3   \n",
      "869          870         1       3   \n",
      "870          871         0       3   \n",
      "871          872         1       1   \n",
      "872          873         0       1   \n",
      "873          874         0       3   \n",
      "874          875         1       2   \n",
      "875          876         1       3   \n",
      "876          877         0       3   \n",
      "877          878         0       3   \n",
      "878          879         0       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "881          882         0       3   \n",
      "882          883         0       3   \n",
      "883          884         0       2   \n",
      "884          885         0       3   \n",
      "885          886         0       3   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                     Moran, Mr. James    male   NaN      0   \n",
      "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
      "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
      "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
      "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
      "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
      "16                                Rice, Master. Eugene    male   2.0      4   \n",
      "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
      "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
      "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
      "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
      "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
      "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
      "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
      "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
      "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
      "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
      "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
      "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
      "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
      "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
      "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
      "864                             Gill, Mr. John William    male  24.0      0   \n",
      "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
      "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
      "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
      "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
      "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
      "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
      "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
      "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
      "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
      "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
      "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
      "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
      "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
      "881                                 Markun, Mr. Johann    male  33.0      0   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
      "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
      "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket      Fare        Cabin Embarked  \n",
      "0        0         A/5 21171    7.2500          NaN        S  \n",
      "1        0          PC 17599   71.2833          C85        C  \n",
      "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
      "3        0            113803   53.1000         C123        S  \n",
      "4        0            373450    8.0500          NaN        S  \n",
      "5        0            330877    8.4583          NaN        Q  \n",
      "6        0             17463   51.8625          E46        S  \n",
      "7        1            349909   21.0750          NaN        S  \n",
      "8        2            347742   11.1333          NaN        S  \n",
      "9        0            237736   30.0708          NaN        C  \n",
      "10       1           PP 9549   16.7000           G6        S  \n",
      "11       0            113783   26.5500         C103        S  \n",
      "12       0         A/5. 2151    8.0500          NaN        S  \n",
      "13       5            347082   31.2750          NaN        S  \n",
      "14       0            350406    7.8542          NaN        S  \n",
      "15       0            248706   16.0000          NaN        S  \n",
      "16       1            382652   29.1250          NaN        Q  \n",
      "17       0            244373   13.0000          NaN        S  \n",
      "18       0            345763   18.0000          NaN        S  \n",
      "19       0              2649    7.2250          NaN        C  \n",
      "20       0            239865   26.0000          NaN        S  \n",
      "21       0            248698   13.0000          D56        S  \n",
      "22       0            330923    8.0292          NaN        Q  \n",
      "23       0            113788   35.5000           A6        S  \n",
      "24       1            349909   21.0750          NaN        S  \n",
      "25       5            347077   31.3875          NaN        S  \n",
      "26       0              2631    7.2250          NaN        C  \n",
      "27       2             19950  263.0000  C23 C25 C27        S  \n",
      "28       0            330959    7.8792          NaN        Q  \n",
      "29       0            349216    7.8958          NaN        S  \n",
      "..     ...               ...       ...          ...      ...  \n",
      "861      0             28134   11.5000          NaN        S  \n",
      "862      0             17466   25.9292          D17        S  \n",
      "863      2          CA. 2343   69.5500          NaN        S  \n",
      "864      0            233866   13.0000          NaN        S  \n",
      "865      0            236852   13.0000          NaN        S  \n",
      "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
      "867      0          PC 17590   50.4958          A24        S  \n",
      "868      0            345777    9.5000          NaN        S  \n",
      "869      1            347742   11.1333          NaN        S  \n",
      "870      0            349248    7.8958          NaN        S  \n",
      "871      1             11751   52.5542          D35        S  \n",
      "872      0               695    5.0000  B51 B53 B55        S  \n",
      "873      0            345765    9.0000          NaN        S  \n",
      "874      0         P/PP 3381   24.0000          NaN        C  \n",
      "875      0              2667    7.2250          NaN        C  \n",
      "876      0              7534    9.8458          NaN        S  \n",
      "877      0            349212    7.8958          NaN        S  \n",
      "878      0            349217    7.8958          NaN        S  \n",
      "879      1             11767   83.1583          C50        C  \n",
      "880      1            230433   26.0000          NaN        S  \n",
      "881      0            349257    7.8958          NaN        S  \n",
      "882      0              7552   10.5167          NaN        S  \n",
      "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
      "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
      "885      5            382652   29.1250          NaN        Q  \n",
      "886      0            211536   13.0000          NaN        S  \n",
      "887      0            112053   30.0000          B42        S  \n",
      "888      2        W./C. 6607   23.4500          NaN        S  \n",
      "889      0            111369   30.0000         C148        C  \n",
      "890      0            370376    7.7500          NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#####################################################################\n",
    "# Reading, Cleaning & Transforming Training Data                    #\n",
    "#####################################################################\n",
    "\n",
    "training_data = pd.read_csv(\"data/raw/train.csv\")\n",
    "print(training_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing some columns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data.drop([\"Name\", \"Ticket\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#####################################################################\n",
    "#Replacing Nan with Mean and Create Indicator Columns for \"Cabin\" and \"Embarked\"   ##\n",
    "#####################################################################\n",
    "\n",
    "tmp = np.round(np.mean(training_data[\"Age\"]))\n",
    "training_data_replaced_nan_with_mean = training_data\n",
    "for i in range(training_data_replaced_nan_with_mean.shape[0]):\n",
    "    if np.isnan(training_data_replaced_nan_with_mean[\"Age\"][i]) == True:\n",
    "        training_data_replaced_nan_with_mean.set_value(i, \"Age\", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch      Fare  \\\n",
       "0              1         0       3    male  22.0      1      0    7.2500   \n",
       "1              2         1       1  female  38.0      1      0   71.2833   \n",
       "2              3         1       3  female  26.0      0      0    7.9250   \n",
       "3              4         1       1  female  35.0      1      0   53.1000   \n",
       "4              5         0       3    male  35.0      0      0    8.0500   \n",
       "5              6         0       3    male  30.0      0      0    8.4583   \n",
       "6              7         0       1    male  54.0      0      0   51.8625   \n",
       "7              8         0       3    male   2.0      3      1   21.0750   \n",
       "8              9         1       3  female  27.0      0      2   11.1333   \n",
       "9             10         1       2  female  14.0      1      0   30.0708   \n",
       "10            11         1       3  female   4.0      1      1   16.7000   \n",
       "11            12         1       1  female  58.0      0      0   26.5500   \n",
       "12            13         0       3    male  20.0      0      0    8.0500   \n",
       "13            14         0       3    male  39.0      1      5   31.2750   \n",
       "14            15         0       3  female  14.0      0      0    7.8542   \n",
       "15            16         1       2  female  55.0      0      0   16.0000   \n",
       "16            17         0       3    male   2.0      4      1   29.1250   \n",
       "17            18         1       2    male  30.0      0      0   13.0000   \n",
       "18            19         0       3  female  31.0      1      0   18.0000   \n",
       "19            20         1       3  female  30.0      0      0    7.2250   \n",
       "20            21         0       2    male  35.0      0      0   26.0000   \n",
       "21            22         1       2    male  34.0      0      0   13.0000   \n",
       "22            23         1       3  female  15.0      0      0    8.0292   \n",
       "23            24         1       1    male  28.0      0      0   35.5000   \n",
       "24            25         0       3  female   8.0      3      1   21.0750   \n",
       "25            26         1       3  female  38.0      1      5   31.3875   \n",
       "26            27         0       3    male  30.0      0      0    7.2250   \n",
       "27            28         0       1    male  19.0      3      2  263.0000   \n",
       "28            29         1       3  female  30.0      0      0    7.8792   \n",
       "29            30         0       3    male  30.0      0      0    7.8958   \n",
       "..           ...       ...     ...     ...   ...    ...    ...       ...   \n",
       "861          862         0       2    male  21.0      1      0   11.5000   \n",
       "862          863         1       1  female  48.0      0      0   25.9292   \n",
       "863          864         0       3  female  30.0      8      2   69.5500   \n",
       "864          865         0       2    male  24.0      0      0   13.0000   \n",
       "865          866         1       2  female  42.0      0      0   13.0000   \n",
       "866          867         1       2  female  27.0      1      0   13.8583   \n",
       "867          868         0       1    male  31.0      0      0   50.4958   \n",
       "868          869         0       3    male  30.0      0      0    9.5000   \n",
       "869          870         1       3    male   4.0      1      1   11.1333   \n",
       "870          871         0       3    male  26.0      0      0    7.8958   \n",
       "871          872         1       1  female  47.0      1      1   52.5542   \n",
       "872          873         0       1    male  33.0      0      0    5.0000   \n",
       "873          874         0       3    male  47.0      0      0    9.0000   \n",
       "874          875         1       2  female  28.0      1      0   24.0000   \n",
       "875          876         1       3  female  15.0      0      0    7.2250   \n",
       "876          877         0       3    male  20.0      0      0    9.8458   \n",
       "877          878         0       3    male  19.0      0      0    7.8958   \n",
       "878          879         0       3    male  30.0      0      0    7.8958   \n",
       "879          880         1       1  female  56.0      0      1   83.1583   \n",
       "880          881         1       2  female  25.0      0      1   26.0000   \n",
       "881          882         0       3    male  33.0      0      0    7.8958   \n",
       "882          883         0       3  female  22.0      0      0   10.5167   \n",
       "883          884         0       2    male  28.0      0      0   10.5000   \n",
       "884          885         0       3    male  25.0      0      0    7.0500   \n",
       "885          886         0       3  female  39.0      0      5   29.1250   \n",
       "886          887         0       2    male  27.0      0      0   13.0000   \n",
       "887          888         1       1  female  19.0      0      0   30.0000   \n",
       "888          889         0       3  female  30.0      1      2   23.4500   \n",
       "889          890         1       1    male  26.0      0      0   30.0000   \n",
       "890          891         0       3    male  32.0      0      0    7.7500   \n",
       "\n",
       "           Cabin Embarked  \n",
       "0            NaN        S  \n",
       "1            C85        C  \n",
       "2            NaN        S  \n",
       "3           C123        S  \n",
       "4            NaN        S  \n",
       "5            NaN        Q  \n",
       "6            E46        S  \n",
       "7            NaN        S  \n",
       "8            NaN        S  \n",
       "9            NaN        C  \n",
       "10            G6        S  \n",
       "11          C103        S  \n",
       "12           NaN        S  \n",
       "13           NaN        S  \n",
       "14           NaN        S  \n",
       "15           NaN        S  \n",
       "16           NaN        Q  \n",
       "17           NaN        S  \n",
       "18           NaN        S  \n",
       "19           NaN        C  \n",
       "20           NaN        S  \n",
       "21           D56        S  \n",
       "22           NaN        Q  \n",
       "23            A6        S  \n",
       "24           NaN        S  \n",
       "25           NaN        S  \n",
       "26           NaN        C  \n",
       "27   C23 C25 C27        S  \n",
       "28           NaN        Q  \n",
       "29           NaN        S  \n",
       "..           ...      ...  \n",
       "861          NaN        S  \n",
       "862          D17        S  \n",
       "863          NaN        S  \n",
       "864          NaN        S  \n",
       "865          NaN        S  \n",
       "866          NaN        C  \n",
       "867          A24        S  \n",
       "868          NaN        S  \n",
       "869          NaN        S  \n",
       "870          NaN        S  \n",
       "871          D35        S  \n",
       "872  B51 B53 B55        S  \n",
       "873          NaN        S  \n",
       "874          NaN        C  \n",
       "875          NaN        C  \n",
       "876          NaN        S  \n",
       "877          NaN        S  \n",
       "878          NaN        S  \n",
       "879          C50        C  \n",
       "880          NaN        S  \n",
       "881          NaN        S  \n",
       "882          NaN        S  \n",
       "883          NaN        S  \n",
       "884          NaN        S  \n",
       "885          NaN        Q  \n",
       "886          NaN        S  \n",
       "887          B42        S  \n",
       "888          NaN        S  \n",
       "889         C148        C  \n",
       "890          NaN        Q  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_replaced_nan_with_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#####################################################################\n",
    "# Data Visualization                                                #\n",
    "#####################################################################\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "ax1 = plt.subplot2grid((4,2), (0, 0))\n",
    "ax1 = sns.distplot(training_data[\"Survived\"], kde=False)\n",
    "plt.title(\"Histogram\")\n",
    "ax2 = plt.subplot2grid((4,2), (0, 1))\n",
    "ax2 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Pclass\"])\n",
    "plt.title(\"Variation of Survived with Pclass\")\n",
    "ax3 = plt.subplot2grid((4,2), (1, 0))\n",
    "ax3 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Sex\"])\n",
    "plt.title(\"Variation of Survived with Sex\")\n",
    "ax4 = plt.subplot2grid((4,2), (1, 1))\n",
    "ax4 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Age\"])\n",
    "plt.title(\"Variation of Survived with Age\")\n",
    "ax5 = plt.subplot2grid((4,2), (2, 0))\n",
    "ax5 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"SibSp\"])\n",
    "plt.title(\"Variation of Survived with SibSp\")\n",
    "ax6 = plt.subplot2grid((4,2), (2, 1))\n",
    "ax6 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Parch\"])\n",
    "plt.title(\"Variation of Survived with Parch\")\n",
    "ax7 = plt.subplot2grid((4,2), (3, 0), colspan=2)\n",
    "ax7 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Fare\"])\n",
    "plt.title(\"Variation of Survived with Fare\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Building the Tree Model: \n",
    "\n",
    "Now we will read the training and testing data, separate the dependent variable (y) column and use Scikit learn to build a Decision Tree model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# reading the Training Dataset and the Testing DataSet          #\n",
    "#####################################################################\n",
    "train = pd.read_csv(\"data/raw/cleaned_decomposed_training_data_replaced_nan_with_mean.csv\")\n",
    "test = pd.read_csv(\"data/raw/cleaned_decomposed_testing_data_replaced_nan_with_mean.csv\")\n",
    "\n",
    "all_columns = train.columns\n",
    "tabu_list = [\"PassengerId\", \"Survived\", \"Pclass\", \"Sex\", \"Cabin\", \"Embarked\"]\n",
    "x_columns = []\n",
    "for i in range(len(all_columns)):\n",
    "    if all_columns[i] in tabu_list:\n",
    "        continue\n",
    "    else:\n",
    "        x_columns.append(i)\n",
    "x_columns = np.sort(x_columns)\n",
    "\n",
    "train_X = train[x_columns].values\n",
    "train_y = train[\"Survived\"].values\n",
    "\n",
    "test_X = test[x_columns].values\n",
    "test_y = test[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-44e2e31908bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdt_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdt_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdt_model_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_model_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "### Decision Tree Classification                                  ###\n",
    "#####################################################################\n",
    "\n",
    "dt_model = DecisionTreeClassifier(criterion = 'gini', splitter='best', max_depth=None, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=10)\n",
    "dt_model.fit(train_X, train_y)\n",
    "dt_model_predictions = dt_model.predict(test_X)\n",
    "print(dt_model_predictions)\n",
    "dt_confusion_matrix = confusion_matrix(test_y, dt_model_predictions)\n",
    "print(dt_confusion_matrix)\n",
    "#println(\"Accuracy of Decision Tree Classifier = $(sum(dt_model_predictions .== y_values_replaced_nan_with_mean_validation_set) / length(y_values_replaced_nan_with_mean_validation_set))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 13 12 12 12 12 15 12 15 13  8 17 15 12 12  7 12 12 12 12 17 12 15 12 10\n",
      " 12 13 12 12 12 12 15 12 12 12 12 13 12 13 12 15 12 12 12 12 12 12 12 12 10\n",
      " 15 12 15 12 17 15 17 17 13 13 12 13 15 12 12 13 12 17 12 13 12 12 13 13 12\n",
      " 12 12 15 12 10 12 12 12 15 12 13 13 12 17 12 12 12 13 17 12 12 17 12 13 12\n",
      " 12 12 13 12 13 12 13 12 13 13 10 13 12 12 12 12 15 12 12 13 12 12 12 12 12\n",
      " 12 17 12 12 18 12 17 15 12 17 12 12 12 12 15 17 13 17 12 12 17 12 12 17 12\n",
      " 17 12 12 12 13 12 17 12 12 13 12 13 12 17 12  8 12 15 12 12 13 13 13 15 12\n",
      " 10 15 12]\n",
      "[[ 0.03703704  0.96296296]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.92857143  0.07142857]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.94444444  0.05555556]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.94444444  0.05555556]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.94444444  0.05555556]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.94444444  0.05555556]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.875       0.125     ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.5625      0.4375    ]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.92857143  0.07142857]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.03703704  0.96296296]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]\n",
      " [ 0.94444444  0.05555556]\n",
      " [ 0.39583333  0.60416667]\n",
      " [ 0.86725664  0.13274336]]\n",
      "0.870786516854\n"
     ]
    }
   ],
   "source": [
    "dt_apply = dt_model.apply(test_X)  # Returns the index of the leaf that each sample is predicted as.\n",
    "print(dt_apply)\n",
    "dt_dp = dt_model.decision_path(test_X) #Return the decision path in the tree\n",
    "#dt_logProb = dt_model.predict_log_proba(test_X) #Predict class log-probabilities of the input samples X.\n",
    "dt_prob = dt_model.predict_proba(test_X) #Predict class probabilities of the input samples X.\n",
    "print(dt_prob)\n",
    "dt_score = dt_model.score(test_X, test_y) #Returns the mean accuracy on the given test data and labels.\n",
    "print(dt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "#import pygraphviz as pgv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "from IPython.display import Image  \n",
    "\n",
    "#export_graphviz(dt_model, out_file = \"tree.dot\", feature_names = )\n",
    "dot_data = tree.export_graphviz(dt_model, out_file=None,  filled=True, rounded=True, special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "#Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 2.4  Advantages of Decision Trees:\n",
    "Some advantages of decision trees are:\n",
    "\n",
    "1. Non Parametric\n",
    "1. Easily interpretable. Trees can be visualised.\n",
    "2. Require little data preparation.\n",
    "3. Fast to train, fast to predict. Complexity --> $\\phi (pN\\text{log}^2 N)$\n",
    "4. Able to handle both numerical and categorical data. \n",
    "5. Able to handle multi-output problems.\n",
    "6. Use a white box model.\n",
    "\n",
    "\n",
    "## 2.5  Disadvantages of Decision Trees:\n",
    "\n",
    "1. Overfitting. Limit the minimum number of samples required at a leaf node or set the maximum depth of the tree.\n",
    "2. High Variance. Sensitive to small variations in data. This problem is mitigated by ensemble models.\n",
    "3. The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. This can be mitigated by training multiple trees in an ensemble learner, where the features and samples are randomly sampled with replacement.\n",
    "4. Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. Ensemble Models\n",
    "\n",
    "bagging, boosting etc! Models that consist of multiple learners.\n",
    "\n",
    "## 3.1 Random Forests: \n",
    "\n",
    "1. In random forests, each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. \n",
    "2. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. \n",
    "3. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but\n",
    "4. Due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.\n",
    "\n",
    "The scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/images/4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why More Trees?\n",
    "## Why Randomization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/images/5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2 Using Scikit learn for Ensemble Models:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-54196d60e1f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mrf_model_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_model_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "### Random Forest Classification                                  ###\n",
    "#####################################################################\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=50)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_model_predictions = rf_model.predict(test_X)\n",
    "print(rf_model_predictions)\n",
    "rf_confusion_matrix = confusion_matrix(test_y, rf_model_predictions)\n",
    "print(dt_confusion_matrix)\n",
    "#println(\"Accuracy of Decision Tree Classifier = $(sum(dt_model_predictions .== y_values_replaced_nan_with_mean_validation_set) / length(y_values_replaced_nan_with_mean_validation_set))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[310 343 246 ..., 117 368 100]\n",
      " [211 243  27 ..., 249 187  76]\n",
      " [ 80  82 161 ..., 212 232 177]\n",
      " ..., \n",
      " [301 184 129 ...,  23  99 334]\n",
      " [287 212 126 ..., 270 308 275]\n",
      " [ 33 165 219 ...,  80  45 143]]\n",
      "[[ 0.          1.        ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.87433333  0.12566667]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.54        0.46      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 0.64        0.36      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.46        0.54      ]\n",
      " [ 0.14        0.86      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.66        0.34      ]\n",
      " [ 0.74        0.26      ]\n",
      " [ 0.76666667  0.23333333]\n",
      " [ 0.90666667  0.09333333]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.96866667  0.03133333]\n",
      " [ 0.1         0.9       ]\n",
      " [ 0.88        0.12      ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.995       0.005     ]\n",
      " [ 0.78        0.22      ]\n",
      " [ 0.68        0.32      ]\n",
      " [ 0.88        0.12      ]\n",
      " [ 0.56        0.44      ]\n",
      " [ 0.515       0.485     ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.77733333  0.22266667]\n",
      " [ 0.88        0.12      ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.49333333  0.50666667]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.54        0.46      ]\n",
      " [ 0.6         0.4       ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.53566667  0.46433333]\n",
      " [ 0.74        0.26      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.742       0.258     ]\n",
      " [ 0.76666667  0.23333333]\n",
      " [ 0.88        0.12      ]\n",
      " [ 0.48        0.52      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.78        0.22      ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.88        0.12      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.19938276  0.80061724]\n",
      " [ 0.58        0.42      ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.14        0.86      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.66        0.34      ]\n",
      " [ 0.67666667  0.32333333]\n",
      " [ 0.          1.        ]\n",
      " [ 0.32        0.68      ]\n",
      " [ 0.985       0.015     ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.76666667  0.23333333]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.96992063  0.03007937]\n",
      " [ 1.          0.        ]\n",
      " [ 0.53566667  0.46433333]\n",
      " [ 0.46        0.54      ]\n",
      " [ 0.87277778  0.12722222]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.58        0.42      ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.84        0.16      ]\n",
      " [ 0.98992063  0.01007937]\n",
      " [ 0.812       0.188     ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.54        0.46      ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.74        0.26      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.68        0.32      ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.24        0.76      ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.18        0.82      ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.88645987  0.11354013]\n",
      " [ 0.83911822  0.16088178]\n",
      " [ 0.19938276  0.80061724]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.97666667  0.02333333]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.99538462  0.00461538]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.68        0.32      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.78        0.22      ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.572       0.428     ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.46        0.54      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.72        0.28      ]\n",
      " [ 0.89533333  0.10466667]\n",
      " [ 0.94666667  0.05333333]\n",
      " [ 0.72        0.28      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.88        0.12      ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.84        0.16      ]\n",
      " [ 0.58        0.42      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.89533333  0.10466667]\n",
      " [ 0.24        0.76      ]\n",
      " [ 0.932       0.068     ]\n",
      " [ 0.92        0.08      ]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.96992063  0.03007937]\n",
      " [ 0.24        0.76      ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 0.16        0.84      ]\n",
      " [ 0.06        0.94      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.8         0.2       ]\n",
      " [ 0.78        0.22      ]\n",
      " [ 0.92303968  0.07696032]]\n",
      "0.825842696629\n"
     ]
    }
   ],
   "source": [
    "rf_apply = rf_model.apply(test_X)  # Returns the index of the leaf that each sample is predicted as.\n",
    "print(rf_apply)\n",
    "rf_dp = rf_model.decision_path(test_X) #Return the decision path in the tree\n",
    "#dt_logProb = dt_model.predict_log_proba(test_X) #Predict class log-probabilities of the input samples X.\n",
    "rf_prob = rf_model.predict_proba(test_X) #Predict class probabilities of the input samples X.\n",
    "print(rf_prob)\n",
    "rf_score = rf_model.score(test_X, test_y) #Returns the mean accuracy on the given test data and labels.\n",
    "print(rf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Advantags of Random Forest :  \n",
    "\n",
    "1. Off the shelf, no tuning required\n",
    "2. Control of Bias and Variance through the extent of randomization\n",
    "3. Moderately fast\n",
    "4. Good for Parralelization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
