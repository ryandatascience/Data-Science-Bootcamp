{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desciption:\n",
    "#### The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "#### One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "#### In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook will show basic examples of:\n",
    "### Data Handling\n",
    "#### - Importing Data with Pandas\n",
    "#### - Cleaning Data\n",
    "#### - Exploring Data through Visualizations with Matplotlib\n",
    "### Data Analysis\n",
    "#### - Logit Regression Model (Using Scikit learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessarry packages \n",
    "#################################################\n",
    "# Handling data frame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "sns.set(font_scale=1.25)\n",
    "\n",
    "### Linear Regression Model\n",
    "from sklearn.preprocessing import Imputer, LabelBinarizer, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "###############################################################################\n",
    "# Read, Cleaning & transforming Data\n",
    "###############################################################################\n",
    "# Read\n",
    "training_data = pd.read_csv('../../data/train.csv')\n",
    "\n",
    "# Cleaning\n",
    "## Remove unnecessary colums\n",
    "training_data.drop([\"Name\", \"Ticket\"], axis=1, inplace = True)\n",
    "\n",
    "Pclass = np.sort(list(set(training_data[\"Pclass\"])))\n",
    "for i in range(len(Pclass)):\n",
    "    training_data[\"Pclass_\" + str(i+1)] = [ 1 if training_data[\"Pclass\"][j]==Pclass[i] else 0 for j in range(training_data.shape[0])]\n",
    "\n",
    "Sex = np.sort(list(set(training_data[\"Sex\"])))\n",
    "for i in range(len(Sex)):\n",
    "    training_data[\"Sex_\" + str(i+1)] = [ 1 if training_data[\"Sex\"][j]==Sex[i] else 0 for j in range(training_data.shape[0])]\n",
    "\n",
    "#Cabin = np.sort(list(set(training_data[\"Cabin\"])))\n",
    "#Cabin = Cabin[0:len(Cabin)-1]\n",
    "#for i in range(len(Cabin)):\n",
    "#    training_data[\"Cabin_\" + str(i+1)] = [ 1 if training_data[\"Cabin\"][j]==Cabin[i] else 0 for j in range(training_data.shape[0])]\n",
    "\n",
    "Embarked = np.sort(list(set(training_data[\"Embarked\"])))\n",
    "Embarked = Embarked[0:len(Embarked)-1]\n",
    "for i in range(len(Embarked)):\n",
    "    training_data[\"Embarked_\" + str(i+1)] = [ 1 if training_data[\"Embarked\"][j]==Embarked[i] else 0 for j in range(training_data.shape[0])]\n",
    "\n",
    "### handle NA value (missing value)\n",
    "#####################################################################\n",
    "## Strategy 1: Removing Nan                                        ##\n",
    "#####################################################################\n",
    "\n",
    "training_data_removed_nan = training_data[~np.isnan(training_data.Age)]\n",
    "\n",
    "#####################################################################\n",
    "## Strategy 2: Replacing Nan with Mean                             ##\n",
    "#####################################################################\n",
    "\n",
    "tmp = np.round(np.mean(training_data[\"Age\"]))\n",
    "training_data_replaced_nan_with_mean = training_data\n",
    "for i in range(training_data_replaced_nan_with_mean.shape[0]):\n",
    "    if np.isnan(training_data_replaced_nan_with_mean[\"Age\"][i]) == True:\n",
    "        training_data_replaced_nan_with_mean.set_value(i, \"Age\", tmp)\n",
    "                                          \n",
    "#####################################################################\n",
    "## Strategy 3: Replacing Nan with Median                           ##\n",
    "#####################################################################\n",
    "\n",
    "tmp = np.round(np.median(training_data[\"Age\"]))\n",
    "training_data_replaced_nan_with_median = training_data\n",
    "for i in range(training_data_replaced_nan_with_median.shape[0]):\n",
    "    if np.isnan(training_data_replaced_nan_with_median[\"Age\"][i]) == True:\n",
    "        training_data_replaced_nan_with_median.set_value(i, \"Age\", tmp)\n",
    "        \n",
    "# You want to save data to file? \n",
    "#training_data.to_csv(\"../../data/cleaned_train_removed_nan_python.csv\")\n",
    "#training_data_replaced_nan_with_mean.to_csv(\"../../data/cleaned_train_replaced_nan_with_mean_python.csv\")\n",
    "#training_data_replaced_nan_with_median.to_csv(\"../../data/cleaned_train_replaced_nan_with_median_python.csv\")\n",
    "\n",
    "#####################################################################\n",
    "# Data Visualization                                                #\n",
    "#####################################################################\n",
    "# Normal Matplotlib plot\n",
    "plt.figure(figsize=(10, 20))\n",
    "# plots a bar graph of those who surived vs those who did not. \n",
    "ax1 = plt.subplot2grid((5,2),(0,0))              \n",
    "ax1 = training_data.Survived.value_counts().plot(kind='bar')\n",
    "plt.title(\"Distribution of Survival, (1 = Survived)\")    \n",
    "\n",
    "ax2 = plt.subplot2grid((5,2),(0,1))\n",
    "ax2 = plt.scatter(training_data.Survived, training_data.Age)\n",
    "plt.ylabel(\"Age\")                          \n",
    "#plt.grid(b=True, which='major', axis='y')  \n",
    "plt.title(\"Survival by Age,  (1 = Survived)\")\n",
    "\n",
    "# Plot from Seaborn package\n",
    "ax3 = plt.subplot2grid((5,2), (1, 0))\n",
    "ax3 = sns.distplot(training_data[\"Survived\"], kde=False)\n",
    "plt.title(\"Histogram\")\n",
    "\n",
    "ax4 = plt.subplot2grid((5,2), (1, 1))\n",
    "ax4 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Pclass\"])\n",
    "plt.title(\"Variation of Survived with Pclass\")\n",
    "\n",
    "ax5 = plt.subplot2grid((5,2), (2, 0))\n",
    "ax5 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Sex\"])\n",
    "plt.title(\"Variation of Survived with Sex\")\n",
    "\n",
    "ax6 = plt.subplot2grid((5,2), (2, 1))\n",
    "ax6 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Age\"])\n",
    "plt.title(\"Variation of Survived with Age\")\n",
    "\n",
    "ax7 = plt.subplot2grid((5,2), (3, 0))\n",
    "ax7 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"SibSp\"])\n",
    "plt.title(\"Variation of Survived with SibSp\")\n",
    "\n",
    "ax8 = plt.subplot2grid((5,2), (3, 1))\n",
    "ax8 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Parch\"])\n",
    "plt.title(\"Variation of Survived with Parch\")\n",
    "\n",
    "ax9 = plt.subplot2grid((5,2), (4, 0), colspan=2)\n",
    "ax9 = sns.boxplot(x=training_data[\"Survived\"], y=training_data[\"Fare\"])\n",
    "plt.title(\"Variation of Survived with Fare\")\n",
    "plt.tight_layout()\n",
    "\n",
    "#####################################################################\n",
    "# Splitting Training Dataset into Training and Testing Set          #\n",
    "#####################################################################\n",
    "\n",
    "all_columns = training_data.columns\n",
    "tabu_list = [\"PassengerId\", \"Survived\", \"Pclass\", \"Sex\", \"Cabin\", \"Embarked\"]\n",
    "x_columns = []\n",
    "for i in range(len(all_columns)):\n",
    "    if all_columns[i] in tabu_list:\n",
    "        continue\n",
    "    else:\n",
    "        x_columns.append(i)\n",
    "x_columns = np.sort(x_columns)\n",
    "#####################################################################\n",
    "## Strategy 1: Removing Nan                                        ##\n",
    "#####################################################################\n",
    "x_values_removed_nan = training_data_removed_nan[x_columns].values\n",
    "y_values_removed_nan = training_data_removed_nan[\"Survived\"].values\n",
    "x_values_removed_nan_training_set, x_values_removed_nan_validation_set, y_values_removed_nan_training_set, y_values_removed_nan_validation_set = train_test_split(x_values_removed_nan, y_values_removed_nan, test_size=.2)\n",
    "\n",
    "#####################################################################\n",
    "## Strategy 2: Replacing Nan with Mean                             ##\n",
    "#####################################################################\n",
    "x_values_replaced_nan_with_mean = training_data_replaced_nan_with_mean[x_columns].values\n",
    "y_values_replaced_nan_with_mean = training_data_replaced_nan_with_mean[\"Survived\"].values\n",
    "x_values_replaced_nan_with_mean_training_set, x_values_replaced_nan_with_mean_validation_set, y_values_replaced_nan_with_mean_training_set, y_values_replaced_nan_with_mean_validation_set = train_test_split(x_values_replaced_nan_with_mean, y_values_replaced_nan_with_mean, test_size=.2)\n",
    "\n",
    "#####################################################################\n",
    "## Strategy 3: Replacing Nan with Median                           ##\n",
    "#####################################################################\n",
    "x_values_replaced_nan_with_median = training_data_replaced_nan_with_median[x_columns].values\n",
    "y_values_replaced_nan_with_median = training_data_replaced_nan_with_median[\"Survived\"].values\n",
    "x_values_replaced_nan_with_median_training_set, x_values_replaced_nan_with_median_validation_set, y_values_replaced_nan_with_median_training_set, y_values_replaced_nan_with_median_validation_set = train_test_split(x_values_replaced_nan_with_median, y_values_replaced_nan_with_median, test_size=.2)\n",
    "\n",
    "#####################################################################\n",
    "# Models                                                            #\n",
    "#####################################################################\n",
    "\n",
    "#####################################################################\n",
    "## Training with Scikit Learn                                      ##\n",
    "#####################################################################\n",
    "\n",
    "#####################################################################\n",
    "### Logistic Regression                                           ###\n",
    "#####################################################################\n",
    "\n",
    "#####################################################################\n",
    "#### Default Setting                                             ####\n",
    "#####################################################################\n",
    "\n",
    "lr_model = LogisticRegression(fit_intercept=True)\n",
    "lr_model.fit(x_values_replaced_nan_with_mean_training_set, y_values_replaced_nan_with_mean_training_set)\n",
    "lr_model_predictions = lr_model.predict(x_values_replaced_nan_with_mean_validation_set)\n",
    "lr_confusion_matrix = confusion_matrix(y_values_replaced_nan_with_mean_validation_set, lr_model_predictions)\n",
    "\n",
    "print(lr_model.coef_)\n",
    "print(\"Accuracy of Logistic Regression = \" +str((np.sum(lr_model_predictions == y_values_replaced_nan_with_mean_validation_set) / len(y_values_replaced_nan_with_mean_validation_set))*100))\n",
    "print(\"Confusion Matrix of Logistic Regression = \")\n",
    "print(lr_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backup code for upgrading packages (copy and paste to Command Prompt to run)\n",
    "conda install seaborn && conda update pyzmq numpy scipy sympy scikit-learn ipython numba matplotlib pandas blaze jupyter spyder"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
